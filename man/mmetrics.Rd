% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_functions.R
\name{mmetrics}
\alias{mmetrics}
\title{Classification Model Metrics}
\usage{
mmetrics(tag, score, thresh = 0.5, plot = FALSE, size = 2.5,
  roc = FALSE)
}
\arguments{
\item{tag}{Vector. Real known label}

\item{score}{Vector. Predicted value or model's result}

\item{thresh}{Numeric. Value which splits the results for the 
confusion matrix.}

\item{plot}{Boolean. Plot a Confusion Matrix graph?}

\item{size}{Numeric. Change bubble's size if needed}

\item{roc}{Boolean. Plot ROC Curce with AUC?}
}
\description{
This function lets the user get a confusion matrix and accuracy, and 
for for binary classification models: AUC, Precision, Sensitivity, and
Specificity.
}
